# NDLOCR-Lite OCR Server 設定ファイル
# このファイルを config.toml にコピーして編集してください。
# cp config.toml.example config.toml

# ---------------------------------------------------------------------------
[server]
# ---------------------------------------------------------------------------

# 待受ホスト（外部公開する場合は "0.0.0.0"）
host = "127.0.0.1"

# 待受ポート
port = 7860

# ---------------------------------------------------------------------------
[runtime]
# ---------------------------------------------------------------------------

# 推論デバイス。
# "auto" : CUDA → CPU の順で自動選択（推奨）
# "cuda" : CUDA 強制（利用不可の場合は cpu にフォールバック）
# "cpu"  : CPU 強制
device = "auto"

# ---------------------------------------------------------------------------
[processing]
# ---------------------------------------------------------------------------

# PDF の同時処理ページ数。
# この数だけ DEIM 検出器インスタンスが生成されるため、増やすと VRAM 消費が増える。
# CPU 使用率を下げたい場合は 1 に設定する。
page_workers = 2

# PARSEQ バッチ推論モード。
# "auto"  : device = "cuda" なら有効、cpu なら無効（推奨）
# "true"  : 常に有効（CUDA 環境でのみ効果あり）
# "false" : 常に無効（1 行ずつ推論。CPU マルチスレッド動作時はこちらが速い場合がある）
batch_inference = "auto"

# PARSEQ の 1 回の推論に渡す最大行数。
# PARSEQ は AR ループが ONNX グラフ内に完全展開されているため、
# バッチサイズが大きいほど中間テンソルが線形に増加し VRAM を圧迫する。
# これを超える行数は複数パスに分割して処理される。
#   8  → 控えめ（VRAM 約 4GB 前後）
#  16  → 推奨（VRAM 約 5〜6GB 前後）
#  32  → 高速優先（VRAM 約 8GB 前後）
#   0  → 無制限（非推奨）
max_batch = 16

# ---------------------------------------------------------------------------
[vram]
# ---------------------------------------------------------------------------

# リクエスト処理後のセッション解放モード。
# "never"  : 解放しない（デフォルト。warmup 済み環境で推奨）
# "always" : 毎リクエスト後に解放・再ロード（VRAM を他プロセスと共有する場合）
# "auto"   : reload_threshold_gb を超えたときだけ解放・再ロード
reload = "never"

# reload = "auto" のときのリロード閾値（GB）。
# リクエスト処理後の VRAM 使用量がこの値を超えていた場合にセッションを解放・再ロードする。
# 上限の保証ではなく「大きめのドキュメントを処理した後にプールをリセットする」目安として設定する。
# 例: GPU の VRAM が 12GB なら 9.0 程度に設定する。0 は無効。
reload_threshold_gb = 0.0

# ---------------------------------------------------------------------------
[cpu]
# ---------------------------------------------------------------------------

# CPU モード時に onnxruntime が 1 回の演算（行列積など）に使うスレッド数。
# page_workers 分のページが同時に推論を走らせるため、各ワーカーが多数のスレッドを
# 起動するとコアを奪い合い逆に遅くなる。
#  1  : 推奨（page_workers >= 2 の場合）。スレッド競合を避けられる。
# -1  : onnxruntime がコア数に応じて自動設定。page_workers = 1 の場合は有効な場合がある。
intra_op_threads = 1

